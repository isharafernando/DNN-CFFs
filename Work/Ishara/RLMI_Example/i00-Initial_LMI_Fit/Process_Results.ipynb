{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "##  Written by Ishara Fernando   ##\n",
    "##  Revised Date: 01/15/2024     ##\n",
    "###################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from BHDVCS_tf_modified import *\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def create_folders(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created successfully!\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_name}' already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_FLayer_and_cffLayer(model):\n",
    "    LayerF = tf.keras.models.load_model(model, custom_objects={'TotalFLayer': TotalFLayer})\n",
    "\n",
    "    LayerCFFs = tf.keras.Model(inputs=LayerF.input,\n",
    "                                              outputs=LayerF.get_layer('cff_output_layer').output)\n",
    "    return LayerF, LayerCFFs\n",
    "\n",
    "\n",
    "def predict_cffs_and_f(LayerCFFs, LayerF, inputs):\n",
    "    cffs = LayerCFFs.predict(inputs)\n",
    "    f_values = LayerF.predict(inputs)\n",
    "    return cffs, f_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DNNmodels/model0.h5', 'DNNmodels/model1.h5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder = 'DNNmodels'\n",
    "models = [os.path.join(model_folder, f) for f in os.listdir(model_folder) if f.endswith('.h5')]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_file = 'grid_data.csv'\n",
    "grid_df = pd.read_csv(grid_file, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isharauvaubuntu/.local/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 743us/step\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "41/41 [==============================] - 0s 740us/step\n",
      "41/41 [==============================] - 0s 917us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.12250315],\n",
       "        [0.11889568],\n",
       "        [0.10998438],\n",
       "        ...,\n",
       "        [0.06518529],\n",
       "        [0.06272437],\n",
       "        [0.06191026]], dtype=float32),\n",
       " array([[0.11523858],\n",
       "        [0.11170869],\n",
       "        [0.10297896],\n",
       "        ...,\n",
       "        [0.06056129],\n",
       "        [0.0581186 ],\n",
       "        [0.05731045]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_folder = 'DNNmodels'\n",
    "models = [os.path.join(models_folder, f) for f in os.listdir(models_folder) if f.endswith('.h5')]\n",
    "\n",
    "f_predictions = []\n",
    "cff_predictions = []\n",
    "\n",
    "prediction_inputs = grid_df[['QQ', 'x_b', 't', 'phi_x', 'k']].to_numpy()\n",
    "\n",
    "for modelid in models:\n",
    "    tempFLayer, tempCFFsLayer = load_FLayer_and_cffLayer(modelid)\n",
    "    cffs, f_values = predict_cffs_and_f(tempCFFsLayer, tempFLayer, prediction_inputs)\n",
    "    f_predictions.append(f_values)\n",
    "    cff_predictions.append(cffs)\n",
    "    \n",
    "f_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.51348203, -0.2834696 , -0.22276354,  0.05909455],\n",
       "        [-0.51348203, -0.2834696 , -0.22276354,  0.05909455],\n",
       "        [-0.51348203, -0.2834696 , -0.22276354,  0.05909455],\n",
       "        ...,\n",
       "        [-0.44462407, -0.2644032 , -0.20068496, -0.00405996],\n",
       "        [-0.44462407, -0.26440316, -0.20068496, -0.00405995],\n",
       "        [-0.44462407, -0.26440316, -0.20068496, -0.00405995]],\n",
       "       dtype=float32),\n",
       " array([[-0.57580185, -0.2923725 , -0.29095387,  0.05212314],\n",
       "        [-0.57580185, -0.2923725 , -0.29095387,  0.05212314],\n",
       "        [-0.57580185, -0.2923725 , -0.29095387,  0.05212314],\n",
       "        ...,\n",
       "        [-0.4816913 , -0.24285756, -0.22420084, -0.00816674],\n",
       "        [-0.4816913 , -0.24285756, -0.22420087, -0.00816674],\n",
       "        [-0.4816913 , -0.24285756, -0.22420087, -0.00816674]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cff_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_columns_with_acc(folder_path):\n",
    "    # Get a list of all .csv files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Initialize empty dataframes to store the columns from each file\n",
    "    columns_df = {col: pd.DataFrame() for col in ['F', 'ReH', 'ReE', 'ReHt', 'dvcs', 'Acc_ReH', 'Acc_ReE', 'Acc_ReHt', 'Acc_dvcs']}\n",
    "\n",
    "    # Iterate through each .csv file\n",
    "    for file in csv_files:\n",
    "        # Read the current file into a dataframe\n",
    "        current_df = pd.read_csv(os.path.join(folder_path, file))\n",
    "\n",
    "        # Iterate through the desired columns\n",
    "        for col in columns_df.keys():\n",
    "            # Check if the column exists in the current file\n",
    "            if col in current_df.columns:\n",
    "                # Extract the column and add it to the dataframe\n",
    "                columns_df[col][file] = current_df[col]\n",
    "\n",
    "    # Check if there are any columns in columns_df\n",
    "    if not all(df.empty for df in columns_df.values()):\n",
    "        # Calculate the mean and standard deviation for each column\n",
    "        mean_columns = {col: df.mean(axis=1) for col, df in columns_df.items()}\n",
    "        std_columns = {col: df.std(axis=1) for col, df in columns_df.items()}\n",
    "\n",
    "        # Choose any file to get non-'F', 'ReE', 'ReHt', 'dvcs', 'Acc_ReH', 'Acc_ReE', 'Acc_ReHt', 'Acc_dvcs' columns (assuming the structure is the same for all files)\n",
    "        example_file = pd.read_csv(os.path.join(folder_path, csv_files[0]))\n",
    "        non_columns = example_file[['k', 'QQ', 'x_b', 't', 'phi_x']]\n",
    "\n",
    "        # Create the final dataframe with 'k', 'QQ', 'x_b', 't', 'phi_x', mean, and std columns for each desired column\n",
    "        final_df = non_columns.copy()\n",
    "        for col in columns_df.keys():\n",
    "            final_df[f'{col}'] = mean_columns[col]\n",
    "            final_df[f'std_{col}'] = std_columns[col]\n",
    "\n",
    "        return final_df\n",
    "    else:\n",
    "        print(f\"No data found for columns 'F', 'ReH', 'ReE', 'ReHt', 'dvcs', 'Acc_ReH', 'Acc_ReE', 'Acc_ReHt', 'Acc_dvcs' in any of the files.\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def process_columns_without_acc(folder_path):\n",
    "    # Get a list of all .csv files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Initialize empty dataframes to store the columns from each file\n",
    "    columns_df = {col: pd.DataFrame() for col in ['F', 'ReH', 'ReE', 'ReHt', 'dvcs']}\n",
    "\n",
    "    # Iterate through each .csv file\n",
    "    for file in csv_files:\n",
    "        # Read the current file into a dataframe\n",
    "        current_df = pd.read_csv(os.path.join(folder_path, file))\n",
    "\n",
    "        # Iterate through the desired columns\n",
    "        for col in columns_df.keys():\n",
    "            # Check if the column exists in the current file\n",
    "            if col in current_df.columns:\n",
    "                # Extract the column and add it to the dataframe\n",
    "                columns_df[col][file] = current_df[col]\n",
    "\n",
    "    # Check if there are any columns in columns_df\n",
    "    if not all(df.empty for df in columns_df.values()):\n",
    "        # Calculate the mean and standard deviation for each column\n",
    "        mean_columns = {col: df.mean(axis=1) for col, df in columns_df.items()}\n",
    "        std_columns = {col: df.std(axis=1) for col, df in columns_df.items()}\n",
    "\n",
    "        # Choose any file to get non-'F', 'ReE', 'ReHt', 'dvcs' columns (assuming the structure is the same for all files)\n",
    "        example_file = pd.read_csv(os.path.join(folder_path, csv_files[0]))\n",
    "        non_columns = example_file[['k', 'QQ', 'x_b', 't', 'phi_x']]\n",
    "\n",
    "        # Create the final dataframe with 'k', 'QQ', 'x_b', 't', 'phi_x', mean, and std columns for each desired column\n",
    "        final_df = non_columns.copy()\n",
    "        for col in columns_df.keys():\n",
    "            final_df[f'{col}'] = mean_columns[col]\n",
    "            final_df[f'std_{col}'] = std_columns[col]\n",
    "\n",
    "        return final_df\n",
    "    else:\n",
    "        print(f\"No data found for columns 'F', 'ReH', 'ReE', 'ReHt', 'dvcs' in any of the files.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we generate a single file with the average values from all replica models ###\n",
    "replicatestdf = process_columns_with_acc('Replica_Results')\n",
    "replicatestdf.to_csv('Replica_summmary_i01.csv')\n",
    "\n",
    "## Here we generate a single file with projected average values from all replica models ##\n",
    "## for the grid-values (2D fine-binned)    ##\n",
    "Projtestdf = process_columns_without_acc('Projections_for_Improve_Model')\n",
    "Projtestdf.to_csv('Projected_pseudodata_i01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_4D_scatter_plot(ax, df, acc_column, acc_range, title):\n",
    "    filtered_df = df[(df[str(acc_column)] > acc_range[0]) & (df[str(acc_column)] <= acc_range[1])]\n",
    "    ax.scatter(filtered_df['x_b'], filtered_df['QQ'], filtered_df['t'], c=filtered_df[str(acc_column)], cmap='viridis')\n",
    "    ax.set_xlabel('x_b')\n",
    "    ax.set_ylabel('QQ')\n",
    "    ax.set_zlabel('t')\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "def Generate_Acc_Kin_Plot(df):\n",
    "    fig = plt.figure(figsize=(20, 25))\n",
    "    \n",
    "    limit_1 = 50\n",
    "    limit_2 = 75\n",
    " \n",
    "    # Scatter plot for accuracy > limit_2\n",
    "    ax1 = fig.add_subplot(4,3,1, projection='3d')\n",
    "    create_4D_scatter_plot(ax1, df, 'Acc_ReH', (limit_2, 100), f'ReH Accuracy > {limit_2}')\n",
    "\n",
    "    # Scatter plot for limit_1 < accuracy <= limit_2\n",
    "    ax2 = fig.add_subplot(4,3,2, projection='3d')\n",
    "    create_4D_scatter_plot(ax2, df, 'Acc_ReH', (limit_1, limit_2), f'{limit_1} < ReH Accuracy <= {limit_2}')\n",
    "\n",
    "    # Scatter plot for 0 < accuracy <= limit_1\n",
    "    ax3 = fig.add_subplot(4,3,3, projection='3d')\n",
    "    create_4D_scatter_plot(ax3, df, 'Acc_ReH', (0, limit_1), f'0 < ReH Accuracy <= {limit_1}')\n",
    "    \n",
    "\n",
    "    # Scatter plot for accuracy > limit_2\n",
    "    ax4 = fig.add_subplot(4,3,4, projection='3d')\n",
    "    create_4D_scatter_plot(ax4, df, 'Acc_ReE', (limit_2, 100), f'ReE Accuracy > {limit_2}')\n",
    "\n",
    "    # Scatter plot for limit_1 < accuracy <= limit_2\n",
    "    ax5 = fig.add_subplot(4,3,5, projection='3d')\n",
    "    create_4D_scatter_plot(ax5, df, 'Acc_ReE', (limit_1, limit_2), f'{limit_1} < ReE Accuracy <= {limit_2}')\n",
    "\n",
    "    # Scatter plot for 0 < accuracy <= limit_1\n",
    "    ax6 = fig.add_subplot(4,3,6, projection='3d')\n",
    "    create_4D_scatter_plot(ax6, df, 'Acc_ReE', (0, limit_1), f'0 < ReE Accuracy <= {limit_1}')\n",
    "\n",
    "    \n",
    "    # Scatter plot for accuracy > limit_2\n",
    "    ax7 = fig.add_subplot(4,3,7, projection='3d')\n",
    "    create_4D_scatter_plot(ax7, df, 'Acc_ReHt', (limit_2, 100), f'ReHt Accuracy > {limit_2}')\n",
    "\n",
    "    # Scatter plot for limit_1 < accuracy <= limit_2\n",
    "    ax8 = fig.add_subplot(4,3,8, projection='3d')\n",
    "    create_4D_scatter_plot(ax8, df, 'Acc_ReHt', (limit_1, limit_2), f'{limit_1} < ReHt Accuracy <= {limit_2}')\n",
    "\n",
    "    # Scatter plot for 0 < accuracy <= limit_1\n",
    "    ax9 = fig.add_subplot(4,3,9, projection='3d')\n",
    "    create_4D_scatter_plot(ax9, df, 'Acc_ReHt', (0, limit_1), f'0 < ReHt Accuracy <= {limit_1}')\n",
    "    \n",
    "\n",
    "    # Scatter plot for accuracy > limit_2\n",
    "    ax10 = fig.add_subplot(4,3,10, projection='3d')\n",
    "    create_4D_scatter_plot(ax10, df, 'Acc_dvcs', (limit_2, 100), f'dvcs Accuracy > {limit_2}')\n",
    "\n",
    "    # Scatter plot for limit_1 < accuracy <= limit_2\n",
    "    ax11 = fig.add_subplot(4,3,11, projection='3d')\n",
    "    create_4D_scatter_plot(ax11, df, 'Acc_dvcs', (limit_1, limit_2), f'{limit_1} < dvcs Accuracy <= {limit_2}')\n",
    "\n",
    "    # Scatter plot for 0 < accuracy <= limit_1\n",
    "    ax12 = fig.add_subplot(4,3,12, projection='3d')\n",
    "    create_4D_scatter_plot(ax12, df, 'Acc_dvcs', (0, limit_1), f'0 < dvcs Accuracy <= {limit_1}')\n",
    "    \n",
    "    plt.savefig('Average_Accuracy_kinematics_combined.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "Generate_Acc_Kin_Plot(replicatestdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_4D_scatter_plot_HTML(df, acc_column, acc_range, title, filename):\n",
    "    filtered_df = df[(df[acc_column] > acc_range[0]) & (df[acc_column] <= acc_range[1])]\n",
    "    fig = px.scatter_3d(filtered_df, x='x_b', y='QQ', z='t', color=acc_column, title=title, color_continuous_scale='viridis')\n",
    "    fig.update_layout(scene=dict(xaxis_title='x_b', yaxis_title='QQ', zaxis_title='t'))\n",
    "    fig.write_html(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_4D_scatter_plot_HTML(replicatestdf, 'Acc_ReH', (0, 100), 'ReH Accuracy', 'kinematics_ReH_Accuracy.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
